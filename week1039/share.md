## Share - 年终非正式总结

又是一年年终，年年做总结做规划，发现最大的结论是，规划目标总是完不成...， 那就不看目标了，只去记录一下今年觉得还行的事。

### 工作

* 年初谈去年绩效
* 自学并应用了Spark, Hive, Airflow
* 学了React ，尝试了Nest.js, Next.js, Express.js 

### 生活

* 想明白了一些事



**先说工作绩效**。

当我得知我的绩效并不好时候， 虽然我知道并非完全不合理，但是我还是觉得要为自己据理力争一回，于是约了领导谈话。主要表达就是相比去年承担了更多的工作与责任，付出了更多的精力，可是绩效却比去年差。领导的回答虽然实在，但是令人失望。他主要意思是人多不可能精确评估每个人的绩效，只能根据开会出勤面熟度来确定，所以不公平是在所难免。 对这个回答，我感谢他的诚实回答，但是对他对此事无丝毫作为感到失望。 最后只能告诫自己，职场这类事多了去，还是自己好好努力，争取跳出这个圈。

然后是几个月后，领导在老板支持下，带出一部分业务独立创业，也邀请我过去。当时我虽然心里仍有芥蒂，但是想到能相对更自由做自己的工作，也是比较倾向去的，他看到我犹豫，开始说去了后年终奖肯定比现在多， 我瞬间觉得不那么想去了， 我是喜欢钱，但我更喜欢能自由开心的做事，不唯金钱论。最后拒绝了他。 



**自学了Spark,Airflow**

主要工作内容是数据开发，数据仓库层维度建模，学习了Kimball 的维度建模理论，开始有意识的对已存在的业务数据做数据分层开发，之后发现，使用的Airflow调度非常好，因为它可以支持代码开发，这可以有更大灵活性组织任务依赖于调度。

最开始使用Hive SQL来操作hadoop,  其实就是写sql 对ods数据进行DW建设，最后生成集市层数据，供BI、财务等使用，期间虽然任务多时间少，但是有机会就会去实现这一过程。之后做离线任务，总是绕不过去Spark, 学习了使用Spark, 并把之前的Hive SQL 任务全换成了Spark SQL ，显著提高了速度。 最开始使用的Scala 来调度Spark, 后来发现结合Airflow更合适的是用pySpark, 因为相比scala打jar包执行，pySpark源代码可见，也更简便。



**学了React, 尝试了Nest.js ,Next.js**

这里的时间重点是学了React.  为啥会考虑学前端， 因为作为后端程序员，独立开发产品的话，前端是避免不了的。  之前学过一段Vue，这次就尝试了React， 根据视频、文档学到了最新的Hook特性。 之后衍生的Next.js ， 和后端的Nest.js ，很像Springmvc 的框架。最终的结果是，还没学的足够好，还无法独立做前端项目。并且Typescript 还没有学。



**生活的琐事**

其实并没有想明白啥，不确定以后想法是否还会变。

最主要的想法是，想要做事的方向比以前清晰了。即在有选择的前提下，选择自认为对社会更有意义的事，能带来福祉的事。比如，有医学计算机研究岗和现金贷岗，金额差距不大，优先选医学岗。并不是说挣钱不重要，而是当前的现实情况下，挣大钱的机会不存在于目前的按部就班上班的工作中，这样的话就去选择能带给人们更多福祉的工作。

其实个人能力、眼界、辨识度有限，无法分辨出哪些工作更能带来社会福祉，而且个人谈这件事还有些大和空， 但是抱着尽一份力的想法去做事， 比如高息贷款，真的没有积极作用吗？ 给那些需要这钱周转的人一个选择，也是好的一件事。 判断标准一般认为，能否带来效率的提升降低生活成本，能否带来更多公平，能否带来更好的体验等等。

努力发挥个人价值。

不断提高个人能力和见识，发挥个人价值。





































